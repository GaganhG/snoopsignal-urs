name: Manual Reddit Scrape

on:
  workflow_dispatch:     # manual trigger still available
  schedule:
    - cron: '0 4 * * *'  # runs at 04:00 UTC → 06:00 CET every day


jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install praw

      - name: Scrape Reddit with PRAW
        env:
          CLIENT_ID:      ${{ secrets.REDDIT_CLIENT_ID }}
          CLIENT_SECRET:  ${{ secrets.REDDIT_CLIENT_SECRET }}
          USER_AGENT:     ${{ secrets.REDDIT_USER_AGENT }}
          USERNAME:       ${{ secrets.REDDIT_USERNAME }}
          PASSWORD:       ${{ secrets.REDDIT_PASSWORD }}
        run: |
          python - << 'PYCODE'
          import os, json
          import praw
          from prawcore.exceptions import Forbidden

          subs = [line.strip() for line in open('config/subreddits.txt') if line.strip()]

          reddit = praw.Reddit(
              client_id=os.environ['CLIENT_ID'],
              client_secret=os.environ['CLIENT_SECRET'],
              user_agent=os.environ['USER_AGENT'],
              username=os.environ['USERNAME'],
              password=os.environ['PASSWORD']
          )

          reddit.read_only = True

          out = []
          for sub in subs:
              try:
                  for post in reddit.subreddit(sub).hot(limit=50):
                      if post.num_comments > 5 and not post.over_18 and len(post.selftext) < 500:
                          out.append({
                              "post": {
                                  "title": post.title,
                                  "selftext": post.selftext,
                                  "subreddit": sub,
                                  "num_comments": post.num_comments
                              }
                          })
              except Forbidden:
                  print(f"⚠️ Forbidden access to r/{sub}, skipping.")

          with open('output.json', 'w') as f:
              json.dump(out, f, indent=2)
          PYCODE

      - name: Upload scrape result
        uses: actions/upload-artifact@v4
        with:
          name: reddit_scrape_output
          path: output.json
          retention-days: 7
